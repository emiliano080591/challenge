# ADR-0001: Arquitectura de Kopi Debate Bot

## Estado
Aceptado — v0.1.0

## Contexto
Se requiere una API para un chatbot que:
- Mantenga un **debate** defendiendo una postura (“stand your ground”).
- Tenga **memoria corta** por conversación (cohesión en varios turnos).
- Sea **fácil de desplegar** local y en contenedor.
- Incluya **observabilidad** desde el inicio (métricas y logs).
- Evite errores previos: rutas anidadas, conexiones DB no gestionadas, falta de settings, acceso crudo a DB sin ORM, métricas globales no thread-safe.

## Objetivos
- API HTTP con FastAPI (`/api/chat`) < 30s de respuesta.
- Persistencia de conversaciones/mensajes.
- Integración LLM (OpenAI) con prompts de rol y control de temperatura.
- Clean-ish architecture: controllers → service → adapter/repos → infra.
- Observabilidad: Prometheus (/metrics), Grafana (dashboards), Loki (logs).
- Ejecutable local (SQLite) y en Docker (Postgres).

## No objetivos
- UI web del cliente.
- Moderación de contenidos / safety avanzada.
- Multi-tenant o auth de usuarios finales.
- Orquestación de colas o workers asíncronos.

## Diseño
- **FastAPI**: tipado y rendimiento, Pydantic para schemas, OpenAPI gratis.
- **Rutas** en módulos dedicados con `APIRouter` (no funciones anidadas).
- **Dependencias**: `get_db()` con `yield` para sesión por request.
- **Servicio (DebateService)**: orquesta lógica, arma contexto al LLM, mide métricas de dominio.
- **Adapter OpenAI**: encapsula prompts, parámetros (modelo, temperatura, max_tokens), captura `usage` para tokens.
- **Repos SQLAlchemy**: ORM y migraciones (Alembic posible a futuro). Evita SQL crudo; sesiones transaccionales.
- **Settings** con `BaseSettings` + `.env` (sin hardcode).
- **Métricas**: `prometheus-fastapi-instrumentator` para HTTP + counters/histograms de negocio/LLM/DB.
- **Logs**: JSON a stdout → Promtail → Loki; Grafana para explorar.
- **Infra**: `docker-compose.yml` unificado (api, db, prometheus, grafana, loki, promtail).

## Alternativas consideradas
- **Flask**: más simple, pero sin tipado/validación rica por defecto. FastAPI aporta OpenAPI + rendimiento.
- **Sin ORM (sqlite3/psycopg)**: más rápido al inicio, pero difícil de evolucionar; preferimos SQLAlchemy.
- **LangChain/LlamaIndex**: power users, pero overkill para el challenge; un adapter simple basta.
- **Solo logs locales**: Loki agrega valor en correlación con métricas y búsquedas por labels.
- **Docusaurus vs Docsify**: ver sección “Documentación” abajo.

## Trade-offs
- **Complejidad** extra (repos, adapter) vs mantenibilidad y testabilidad.
- **Costo** de OpenAI vs simplicidad (podríamos añadir otros providers vía misma interfaz).
- **SQLite local vs Postgres en contenedor**: dos rutas de DB, pero DX superior.

## Operación
- **Config** por `.env` (OPENAI_API_KEY, OPENAI_MODEL, DATABASE_URL).
- **Escalabilidad**: stateless API; DB única; se puede añadir Redis para rate-limit o caché.
- **Seguridad**: no se exponen llaves; `.env` no se sube. Añadir CORS si hay UI.
- **Observabilidad**: dashboards listos (métricas de negocio/LLM/HTTP/DB), logs en Loki.

## Pruebas
- Unit tests para servicio y repos (mocks del adapter OpenAI y DB in-memory).
- Contratos de API por `response_model`.
- Smoke tests con `curl` y healthcheck.

## Riesgos
- Dependencia del proveedor LLM.
- Tokens/costos si crece el uso (medidos por métricas).
- Cardinalidad de métricas si se etiquetan `topic/stance` (evitar).

## Futuro
- Alembic migrations; índices adicionales.
- Auth/Rate limiting; quotas por conversación.
- Soporte multi-LLM; streaming de tokens.
